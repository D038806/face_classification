{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: UTF-8 -*-\n",
    "import sys\n",
    "import cv2\n",
    "from PyQt5 import QtCore, QtGui, QtWidgets\n",
    "from PyQt5.QtWidgets import *\n",
    "from PyQt5.QtCore import *\n",
    "from PyQt5.QtGui import QPalette, QBrush, QPixmap\n",
    "import os\n",
    "\n",
    "import sys\n",
    "\n",
    "from statistics import mode\n",
    "\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "from utils.datasets import get_labels\n",
    "\n",
    "from utils.inference import detect_faces\n",
    "from utils.inference import draw_text\n",
    "from utils.inference import draw_bounding_box\n",
    "from utils.inference import draw_solid_box\n",
    "from utils.inference import apply_offsets\n",
    "from utils.inference import load_detection_model\n",
    "from utils.preprocessor import preprocess_input\n",
    "\n",
    "from emotion_icon import load_emotion_icon\n",
    "from emotion_icon import Addemotion\n",
    "from emotion_icon import Addemotion_word\n",
    "\n",
    "from DL_args import get_args\n",
    "from keras.utils.data_utils import get_file\n",
    "from contextlib import contextmanager\n",
    "from wide_resnet import WideResNet\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import dlib\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from utils.datasets import get_labels\n",
    "from utils.inference import detect_faces\n",
    "\n",
    "from tkinter import *\n",
    "from PIL import Image,ImageTk\n",
    "from utils.grad_cam import compile_gradient_function\n",
    "from utils.grad_cam import compile_saliency_function\n",
    "from utils.grad_cam import register_gradient\n",
    "from utils.grad_cam import modify_backprop\n",
    "from utils.grad_cam import calculate_guided_gradient_CAM\n",
    "from utils.inference import detect_faces\n",
    "from utils.inference import apply_offsets\n",
    "\n",
    "from utils.datasets import get_class_to_arg\n",
    "from DL_args import get_args\n",
    "\n",
    "\n",
    "import Marquee\n",
    "import tkinter as tk\n",
    "\n",
    "global flag\n",
    "flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},

   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\robert\\Anaconda3\\envs\\emotion_face\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\robert\\Anaconda3\\envs\\emotion_face\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],

   "source": [
    "detection_model_path = '../trained_models/detection_models/haarcascade_frontalface_default.xml'\n",
    "emotion_model_path = '../trained_models/emotion_models/fer2013_mini_XCEPTION.102-0.66.hdf5'\n",
    "gender_model_path = '../trained_models/gender_models/simple_CNN.81-0.96.hdf5'\n",
    "emotion_labels = get_labels('fer2013')\n",
    "gender_labels = get_labels('imdb')\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "face_detection = load_detection_model(detection_model_path)\n",
    "emotion_classifier = load_model(emotion_model_path, compile=False)\n",
    "gender_classifier = load_model(gender_model_path, compile=False)\n",
    "gender_offsets = (30, 60)\n",
    "emotion_offsets = (20, 40)\n",
    "frame_window=10\n",
    "# getting input model shapes for inference\n",
    "emotion_target_size = emotion_classifier.input_shape[1:3]\n",
    "gender_target_size = gender_classifier.input_shape[1:3]\n",
    "icon_dict , words_dict = load_emotion_icon()\n",
    "\n",
    "# starting lists for calculating modes\n",
    "gender_window = []\n",
    "emotion_window = []\n",
    "\n",
    "pretrained_model = \"https://github.com/yu4u/age-gender-estimation/releases/download/v0.5/weights.28-3.73.hdf5\"\n",
    "modhash = 'fbe63257a054c1c5466cfd7bf14646d6'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sad_man\n",
      "33\n",
      "64\n",
      "[ 33 277  64  64]\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robert\\Anaconda3\\envs\\emotion_face\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3299: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "class Ui_MainWindow(QtWidgets.QWidget):\n",
    "    def __init__(self, parent=None):\n",
    "        super(Ui_MainWindow, self).__init__(parent)\n",
    "        \n",
    "        # self.face_recong = face.Recognition()\n",
    "        self.timer_camera = QtCore.QTimer()\n",
    "        self.cap = cv2.VideoCapture()\n",
    "        self.CAM_NUM = 0\n",
    "        self.set_ui()\n",
    "        self.slot_init()\n",
    "        self.__flag_work = 0\n",
    "        self.x =0\n",
    "        self.count = 0\n",
    "\n",
    "    def set_ui(self):\n",
    "        \n",
    "        self.__layout_main = QtWidgets.QVBoxLayout() ##  垂直排版\n",
    "        self.__layout_fun_button = QtWidgets.QHBoxLayout() ##  水平排版\n",
    "        self.__layout_data_show = QtWidgets.QHBoxLayout()\n",
    "        self.__layout_logo_show = QtWidgets.QHBoxLayout()\n",
    "        \n",
    "        ##\n",
    "#         self.lb1 = QtWidgets.QLabel('實現夢想 在中正 ~！',self)\n",
    "#         self.lb1.resize(300,500)\n",
    "#         self.lb1.setFrameStyle(QFrame.Panel | QFrame.Sunken)\n",
    "#         self.lb1.setAlignment(Qt.AlignBottom | Qt.AlignRight)\n",
    "#         self.lb1.resultLabel.setText(\"<h2>實現夢想 在中正 ~！</h2>\")\n",
    "        ##\n",
    "        # Set image on the button  start\n",
    "        ICON_HEIGHT = 300 \n",
    "        ICON_WIDTH = 200\n",
    "        self.button_test = QtWidgets.QPushButton(u'')##  +button\n",

    "        self.button_test.setIcon(QtGui.QIcon('./img/AR.png'))\n",

    "        self.button_test.setIconSize(QtCore.QSize(ICON_HEIGHT,ICON_WIDTH))\n",
    "        \n",
    "        \n",
    "        self.button_open_camera = QtWidgets.QPushButton(u'')\n",

    "        self.button_open_camera.setIcon(QtGui.QIcon('./img/age_gender_emotion.png'))\n",

    "        self.button_open_camera.setIconSize(QtCore.QSize(ICON_HEIGHT,ICON_WIDTH))\n",
    "        \n",
    "        \n",
    "        self.button_close = QtWidgets.QPushButton(u'')\n",
    "        self.button_close.setIcon(QtGui.QIcon('./img/face_fustion.PNG'))\n",
    "        self.button_close.setIconSize(QtCore.QSize(ICON_HEIGHT,ICON_WIDTH))\n",
    "        \n",
    "        # Set image on the button  end\n",
    "        \n",
    "        #Button 的顏色修改\n",
    "        button_color = [self.button_open_camera, self.button_close, self.button_test] ##  +button\n",
    "        for i in range(3):\n",
    "            button_color[i].setStyleSheet(\"QPushButton{color:black}\"\n",
    "                                          \"QPushButton:hover{color:red}\"\n",
    "                                          \"QPushButton{background-color:rgb(0,255,255)}\"\n",
    "                                          \"QPushButton{border:2px}\"\n",
    "                                          \"QPushButton{border-radius:10px}\"\n",
    "                                          \"QPushButton{padding:2px 4px}\")\n",
    "\n",
    "        # set button size\n",
    "        BUTTON_HEIGHT = 250\n",
    "        BUTTON_WIDTH = 40\n",
    "        self.button_open_camera.setMinimumHeight(BUTTON_HEIGHT)\n",
    "        self.button_open_camera.setMinimumWidth(BUTTON_WIDTH)\n",
    "        self.button_close.setMinimumHeight(BUTTON_HEIGHT)\n",
    "        self.button_close.setMinimumWidth(BUTTON_WIDTH)\n",
    "        self.button_test.setMinimumHeight(BUTTON_HEIGHT) # + button\n",
    "        self.button_test.setMinimumWidth(BUTTON_WIDTH)\n",
    "        # move()方法移動視窗在螢幕上的位置到x = 300，y = 300座標。\n",
    "#         self.move(300,300)\n",
    "        self.setGeometry(100, 100, 1217, 684)\n",
    "\n",
    "    \n",
    "        # 全大運圖片\n",
    "        pix = QPixmap('./img/17.png')\n",
    "        self.lb1 = QLabel()\n",
    "        self.lb1.setFixedSize(300,300)\n",
    "        self.lb1.setPixmap(pix)\n",
    "        \n",
    "        pix2 = QPixmap('./img/logo1.jpg')\n",
    "        self.lb2 = QLabel()\n",
    "        self.lb2.setFixedSize(300,330)\n",
    "        self.lb2.setPixmap(pix2)\n",
    "        \n",
    "        \n",
    "        # 資訊顯示\n",
    "        self.label_show_camera = QLabel()\n",
    "        self.label_move = QtWidgets.QLabel()\n",
    "        self.label_move.setFixedSize(80,100)  # Camera　frame　size\n",
    "\n",
    "        self.label_show_camera.setFixedSize(1060, 1000)   # Main frame size\n",
    "        self.label_show_camera.setAutoFillBackground(False)\n",
    "\n",
    "#         self.__layout_fun_button.addWidget(self.label_move)\n",
    "\n",
    "        # layer main\n",
    "#         self.__layout_main.addLayout(self.__layout_data_show)\n",
    "        self.__layout_main.addWidget(self.lb2)\n",
    "        self.__layout_main.addWidget(self.label_show_camera)\n",
    "        self.__layout_main.addLayout(self.__layout_data_show)\n",
    "        self.__layout_main.addLayout(self.__layout_fun_button)\n",
    "        \n",
    "        # Layer data show\n",
    "#         self.__layout_logo_show.addWidget(self.lb2)\n",
    "#         self.__layout_logo_show.addWidget(self.lb2)\n",
    "#         self.__layout_logo_show.addWidget(self.lb2)\n",
    "        \n",
    "        self.__layout_data_show.addWidget(self.lb1)\n",
    "        self.__layout_data_show.addWidget(self.lb1)\n",
    "        self.__layout_data_show.addWidget(self.lb1)\n",
    "        \n",
    "        # layer button\n",
    "        self.__layout_fun_button.addWidget(self.button_open_camera)\n",
    "        self.__layout_fun_button.addWidget(self.button_close)\n",
    "        self.__layout_fun_button.addWidget(self.button_test) ## + button\n",
    "        \n",
    "        self.setLayout(self.__layout_main)\n",
    "        self.label_move.raise_()\n",
    "        self.setWindowTitle(u'攝像頭')\n",
    "\n",
    "        \n",
    "        # 設定背景圖片\n",
    "        palette1 = QPalette()\n",
    "        palette1.setBrush(self.backgroundRole(), QBrush(QPixmap('./img/background_3.jpg')))\n",
    "        self.setPalette(palette1)\n",
    "\n",
    "        \n",
    "\n",
    "    def slot_init(self):\n",
    "        self.button_open_camera.clicked.connect(self.button_open_camera_click)\n",
    "        self.timer_camera.timeout.connect(self.show_camera)\n",
    "        self.button_close.clicked.connect(self.close)\n",
    "        self.button_test.clicked.connect(self.test_click)\n",
    "    \n",
    "    def test_click(self,flag):\n",
    "        \n",
    "#         face_fusion(0)\n",
    "        \n",
    "        if self.timer_camera.isActive() == False:\n",
    "            flag = self.cap.open(self.CAM_NUM)\n",
    "            if flag == False:\n",
    "                msg = QtWidgets.QMessageBox.warning(self, u\"Warning\", u\"請檢測相機與電腦是否連線正確\", buttons=QtWidgets.QMessageBox.Ok,\n",
    "                                                defaultButton=QtWidgets.QMessageBox.Ok)\n",
    "            # if msg==QtGui.QMessageBox.Cancel:\n",
    "            #                     pass\n",
    "            else:\n",
    "                self.timer_camera.start(30)\n",
    "#                 self.button_open_camera.setText(u'關閉相機')\n",
    "        else:\n",
    "            self.timer_camera.stop()\n",
    "            self.cap.release()\n",
    "            self.label_show_camera.clear()\n",
    "#             self.button_open_camera.setText(u'開啟相機')\n",
    "\n",
    "        \n",
    "\n",
    "    def button_open_camera_click(self):\n",
    "        if self.timer_camera.isActive() == False:\n",
    "            flag = self.cap.open(self.CAM_NUM)\n",
    "            if flag == False:\n",
    "                msg = QtWidgets.QMessageBox.warning(self, u\"Warning\", u\"請檢測相機與電腦是否連線正確\", buttons=QtWidgets.QMessageBox.Ok,\n",
    "                                                defaultButton=QtWidgets.QMessageBox.Ok)\n",
    "            # if msg==QtGui.QMessageBox.Cancel:\n",
    "            #                     pass\n",
    "            else:\n",
    "                self.timer_camera.start(30)\n",
    "                self.button_open_camera.setText(u'')\n",
    "        else:\n",
    "            self.timer_camera.stop()\n",
    "            self.cap.release()\n",
    "            self.label_show_camera.clear()\n",
    "#             self.button_open_camera.setText(u'開啟相機')\n",
    "\n",
    "\n",
    "    def show_camera(self):\n",
    "        flag, bgr_image = self.cap.read()\n",
    "        if flag:\n",
    "            gray_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2GRAY)\n",
    "            rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)\n",
    "            faces = detect_faces(face_detection, gray_image)\n",
    "\n",
    "            for face_coordinates in faces:\n",
    "                x1, x2, y1, y2 = apply_offsets(face_coordinates, gender_offsets)\n",
    "                rgb_face = rgb_image[y1:y2, x1:x2]\n",
    "\n",
    "                x1, x2, y1, y2 = apply_offsets(face_coordinates, emotion_offsets)\n",
    "                gray_face = gray_image[y1:y2, x1:x2]\n",
    "                try:\n",
    "                    rgb_face = cv2.resize(rgb_face, (gender_target_size))\n",
    "                    gray_face = cv2.resize(gray_face, (emotion_target_size))\n",
    "                except:\n",
    "                    continue\n",
    "                gray_face = preprocess_input(gray_face, False)\n",
    "                gray_face = np.expand_dims(gray_face, 0)\n",
    "                gray_face = np.expand_dims(gray_face, -1)\n",
    "                emotion_label_arg = np.argmax(emotion_classifier.predict(gray_face))\n",
    "                emotion_text = emotion_labels[emotion_label_arg]\n",
    "\n",
    "\n",
    "                rgb_face = np.expand_dims(rgb_face, 0)\n",
    "                rgb_face = preprocess_input(rgb_face, False)\n",
    "                gender_prediction = gender_classifier.predict(rgb_face)\n",
    "                gender_label_arg = np.argmax(gender_prediction)\n",
    "                gender_text = gender_labels[gender_label_arg]\n",
    "                \n",
    "                set_icon = emotion_text+\"_\"+gender_text\n",
    "        \n",
    "\n",
    "                print(set_icon)\n",
    "                icon_img = icon_dict[set_icon]\n",
    "                words_img = words_dict[set_icon]\n",
    "\n",
    "\n",
    "                \n",
    "                if gender_text == gender_labels[0]:\n",
    "                    color = (0, 0, 255)\n",
    "                else:\n",
    "                    color = (255, 0, 0)\n",
    "        \n",
    "#               if((face_coordinates[0:1]-face_coordinates[2:3])>icon_img[1]):\n",
    "                print(face_coordinates[0])\n",
    "                print(face_coordinates[2])\n",
    "    \n",
    "                draw_bounding_box(face_coordinates, rgb_image, color)\n",
    "                solid_box = draw_solid_box(face_coordinates, rgb_image)\n",
    "                solid_box = Addemotion(face_coordinates,solid_box,icon_img)\n",
    "                solid_box = Addemotion_word(face_coordinates,solid_box,words_img)\n",
    "#                 draw_text(face_coordinates, rgb_image, gender_mode,\n",
    "#                         color, 0, -20, 1, 1)\n",
    "#                 draw_text(face_coordinates, rgb_image, emotion_mode,\n",
    "#                         color, 0, -45, 1, 1)\n",
    "                \n",
    "            show = cv2.resize(rgb_image, (1080, 960))\n",
    "            showImage = QtGui.QImage(show, show.shape[1], show.shape[0], QtGui.QImage.Format_RGB888)\n",
    "            self.label_show_camera.setPixmap(QtGui.QPixmap.fromImage(showImage))\n",
    "    #bgr_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2BGR)\n",
    "    #cv2.imshow('window_frame', bgr_image)\n",
    "    #if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        #exit(0)\n",
    "\n",
    "        \n",
    "    def closeEvent(self, event):\n",
    "        ok = QtWidgets.QPushButton()\n",
    "        cacel = QtWidgets.QPushButton()\n",
    "\n",
    "        msg = QtWidgets.QMessageBox(QtWidgets.QMessageBox.Warning, u\"關閉\", u\"是否關閉！\")\n",
    "\n",
    "        msg.addButton(ok,QtWidgets.QMessageBox.ActionRole)\n",
    "        msg.addButton(cacel, QtWidgets.QMessageBox.RejectRole)\n",
    "        ok.setText(u'確定')\n",
    "\n",
    "        if msg.exec_() == QtWidgets.QMessageBox.RejectRole:\n",
    "            event.ignore()\n",
    "        else:\n",
    "            #             self.socket_client.send_command(self.socket_client.current_user_command)\n",
    "            if self.cap.isOpened():\n",
    "                self.cap.release()\n",
    "            if self.timer_camera.isActive():\n",
    "                self.timer_camera.stop()\n",
    "            event.accept() \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    App = QApplication(sys.argv)\n",
    "    ex = Ui_MainWindow()\n",
    "    ex.show()\n",
    "    sys.exit(App.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
